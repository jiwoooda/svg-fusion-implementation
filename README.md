# SVG Fusion - Complete Implementation

í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì—ì„œ SVG ê·¸ë˜í”½ì„ ìƒì„±í•˜ëŠ” ì™„ì „í•œ êµ¬í˜„ì²´ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- **VP-VAE**: SVG ë²¡í„° í‘œí˜„ê³¼ í”½ì…€ ì„ë² ë”©ì„ ìœµí•©í•˜ëŠ” Vector-Pixel VAE
- **VS-DiT**: í…ìŠ¤íŠ¸ ì¡°ê±´ë¶€ ì ì¬ í™•ì‚° ëª¨ë¸ (Vector Space Diffusion Transformer)
- **ì™„ì „í•œ íŒŒì´í”„ë¼ì¸**: SVG íŒŒì‹± â†’ í›ˆë ¨ â†’ ìƒì„±ê¹Œì§€ ì „ì²´ ê³¼ì • êµ¬í˜„
- **ì‹¤ì œ ì‘ë™**: ë”ë¯¸ ë°ì´í„°ë¡œ ì¦‰ì‹œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ ì´ë™
cd svg_fusion

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ë”ë¯¸ ë°ì´í„° ìƒì„±

```bash
# í…ŒìŠ¤íŠ¸ìš© SVG íŒŒì¼ 50ê°œ ìƒì„±
python create_dummy_data.py --output_dir data/svgs --num_samples 50
```

### 3. VAE í›ˆë ¨

```bash
python train_vae.py \
    --svg_dir data/svgs \
    --batch_size 4 \
    --num_epochs 20 \
    --output_dir checkpoints/vae
```

### 4. DiT í›ˆë ¨

```bash
python train_dit.py \
    --svg_dir data/svgs \
    --vae_checkpoint checkpoints/vae/vpvae_final.pt \
    --batch_size 4 \
    --num_epochs 30 \
    --output_dir checkpoints/dit
```

### 5. SVG ìƒì„±

```bash
python generate.py \
    --vae_checkpoint checkpoints/vae/vpvae_final.pt \
    --dit_checkpoint checkpoints/dit/vsdit_final.pt \
    --prompt "a red circle" \
    --num_samples 4 \
    --output_dir outputs
```

## ğŸ“ ì•„í‚¤í…ì²˜

### VP-VAE (Vector-Pixel VAE)

**Encoder:**
- SVG ìš”ì†Œ ì„ë² ë”© (element_id, command_id, params)
- DINOv2 í”½ì…€ ì„ë² ë”©
- Cross-attention: SVGê°€ í”½ì…€ ì •ë³´ë¥¼ ì¿¼ë¦¬
- Transformer ë ˆì´ì–´
- ì¶œë ¥: Î¼ì™€ log_var

**Decoder:**
- Latent projection
- Transformer ë ˆì´ì–´
- ì¶œë ¥ í—¤ë“œ:
  - Element íƒ€ì… (path, circle, rect, ellipse)
  - Command íƒ€ì… (M, L, C, Z ë“±)
  - ì—°ì† íŒŒë¼ë¯¸í„° (ì¢Œí‘œ, ìŠ¤íƒ€ì¼)

### VS-DiT (Vector Space Diffusion Transformer)

- Timestep ì„ë² ë”©
- Latent projection
- Text context projection (CLIP)
- DiT ë¸”ë¡:
  - AdaLN (timestep-conditioned)
  - Self-attention (latent ì‹œí€€ìŠ¤)
  - Cross-attention (í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸)
  - Feed-forward
- Classifier-Free Guidance (CFG)

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
svg_fusion/
â”œâ”€â”€ models/                     # ëª¨ë¸ êµ¬í˜„
â”‚   â”œâ”€â”€ vpvae.py               # VP-VAE
â”‚   â””â”€â”€ vsdit.py               # VS-DiT
â”œâ”€â”€ utils/                      # ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ svg_parser.py          # SVG íŒŒì‹± ë° í…ì„œ ë³€í™˜
â”‚   â”œâ”€â”€ dataset.py             # ë°ì´í„°ì…‹ í´ë˜ìŠ¤
â”‚   â””â”€â”€ diffusion.py           # Diffusion ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ config.py                   # ì„¤ì •
â”œâ”€â”€ train_vae.py               # VAE í›ˆë ¨
â”œâ”€â”€ train_dit.py               # DiT í›ˆë ¨
â”œâ”€â”€ generate.py                # SVG ìƒì„±
â”œâ”€â”€ create_dummy_data.py       # ë”ë¯¸ ë°ì´í„° ìƒì„±
â””â”€â”€ requirements.txt           # ì˜ì¡´ì„±
```

## ğŸ”§ ì„¤ì •

### VAE ì„¤ì • (`config.py`)

```python
latent_dim = 128               # ì ì¬ ë²¡í„° ì°¨ì›
encoder_d_model = 512          # ì¸ì½”ë” ëª¨ë¸ ì°¨ì›
decoder_d_model = 512          # ë””ì½”ë” ëª¨ë¸ ì°¨ì›
encoder_layers = 4             # ì¸ì½”ë” ë ˆì´ì–´ ìˆ˜
decoder_layers = 4             # ë””ì½”ë” ë ˆì´ì–´ ìˆ˜
num_heads = 8                  # ì–´í…ì…˜ í—¤ë“œ ìˆ˜
max_seq_len = 1024             # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
```

### DiT ì„¤ì •

```python
latent_dim = 128               # VAEì™€ ë™ì¼
hidden_dim = 384               # íˆë“  ì°¨ì›
context_dim = 512              # CLIP ì°¨ì›
num_blocks = 12                # DiT ë¸”ë¡ ìˆ˜
num_heads = 6                  # ì–´í…ì…˜ í—¤ë“œ ìˆ˜
noise_steps = 1000             # Diffusion ìŠ¤í…
```

## ğŸ“Š í›ˆë ¨ íŒŒë¼ë¯¸í„°

### VAE í›ˆë ¨

```bash
python train_vae.py \
    --svg_dir data/svgs \
    --batch_size 8 \
    --num_epochs 50 \
    --lr 1e-4 \
    --weight_decay 0.01 \
    --kl_warmup_steps 5000 \
    --output_dir checkpoints/vae
```

### DiT í›ˆë ¨

```bash
python train_dit.py \
    --svg_dir data/svgs \
    --vae_checkpoint checkpoints/vae/vpvae_final.pt \
    --batch_size 8 \
    --num_epochs 100 \
    --lr 1e-4 \
    --cfg_dropout 0.25 \
    --output_dir checkpoints/dit
```

## ğŸ¨ ìƒì„± íŒŒë¼ë¯¸í„°

```bash
python generate.py \
    --vae_checkpoint checkpoints/vae/vpvae_final.pt \
    --dit_checkpoint checkpoints/dit/vsdit_final.pt \
    --prompt "your text prompt" \
    --num_samples 4 \
    --cfg_scale 7.0 \
    --ddim_steps 100 \
    --output_dir outputs
```

**íŒŒë¼ë¯¸í„° ì„¤ëª…:**
- `cfg_scale`: Classifier-Free Guidance ê°•ë„ (7-15 ê¶Œì¥)
- `ddim_steps`: DDIM ìƒ˜í”Œë§ ìŠ¤í… (50-250)
- `eta`: DDIM í™•ë¥ ì„± (0=ê²°ì •ì , 1=ì™„ì „ í™•ë¥ ì )

## ğŸ”¬ ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

### SVG í‘œí˜„

SVGëŠ” ì‹œí€€ìŠ¤ë¡œ í‘œí˜„ë©ë‹ˆë‹¤:
- **Element ID**: path, circle, rect, ellipse
- **Command ID**: M, L, C, Z ë“±
- **Continuous Params**: ì¢Œí‘œ (8ê°œ) + ìŠ¤íƒ€ì¼ (4ê°œ)
- ëª¨ë“  ê°’ì€ 0-255 binìœ¼ë¡œ ì–‘ìí™”

### DINOv2 í”½ì…€ ì„ë² ë”©

- SVGë¥¼ 224x224 ì´ë¯¸ì§€ë¡œ ë˜ìŠ¤í„°í™”
- DINOv2ë¡œ ì„ë² ë”© ì¶”ì¶œ
- CLS í† í°ì„ ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ë°˜ë³µ

### Diffusion í”„ë¡œì„¸ìŠ¤

- **Forward**: ë…¸ì´ì¦ˆ ì ì§„ì  ì¶”ê°€
- **Reverse**: DDIM ìƒ˜í”Œë§ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
- **CFG**: ì¡°ê±´ë¶€/ë¬´ì¡°ê±´ë¶€ ì˜ˆì¸¡ ë³´ê°„

## ğŸ“ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©

ì‹¤ì œ SVG ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ë ¤ë©´:

1. **SVG íŒŒì¼ ì¤€ë¹„**: `data/svgs/` ë””ë ‰í† ë¦¬ì— ë°°ì¹˜
2. **ìº¡ì…˜ ìƒì„±** (ì„ íƒì‚¬í•­): ê° SVGì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…
3. **í›ˆë ¨**: VAE â†’ DiT ìˆœì„œë¡œ í›ˆë ¨
4. **ìƒì„±**: í›ˆë ¨ëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ SVG ìƒì„±

## âš¡ ì„±ëŠ¥ ìµœì í™”

### GPU ë©”ëª¨ë¦¬ ì ˆì•½

- `--batch_size` ê°ì†Œ (4 ë˜ëŠ” 2)
- `--max_seq_len` ê°ì†Œ (512)
- Gradient checkpointing í™œì„±í™”

### í›ˆë ¨ ì†ë„ í–¥ìƒ

- `--num_workers` ì¦ê°€
- Mixed precision í›ˆë ¨
- ë” ì‘ì€ DINOv2 ëª¨ë¸ ì‚¬ìš©

### ìƒì„± í’ˆì§ˆ í–¥ìƒ

- `--cfg_scale` ì¦ê°€ (10-15)
- `--ddim_steps` ì¦ê°€ (200-250)
- ë” ë§ì€ ì—í­ í›ˆë ¨

## ğŸ› ë¬¸ì œ í•´ê²°

### SVG íŒŒì‹± ì˜¤ë¥˜
- SVG íŒŒì¼ì´ í‘œì¤€ í˜•ì‹ì¸ì§€ í™•ì¸
- ì§€ì›ë˜ëŠ” ìš”ì†Œë§Œ ì‚¬ìš© (path, circle, rect, ellipse)

### Out of Memory
- ë°°ì¹˜ í¬ê¸° ê°ì†Œ
- ì‹œí€€ìŠ¤ ê¸¸ì´ ê°ì†Œ
- Gradient accumulation ì‚¬ìš©

### ìƒì„± í’ˆì§ˆ ë‚®ìŒ
- ë” ë§ì€ í›ˆë ¨ ë°ì´í„° ì‚¬ìš©
- ë” ê¸´ í›ˆë ¨
- CFG scale ì¡°ì •

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ™ ê°ì‚¬

- DINOv2: Meta AI
- CLIP: OpenAI
- Diffusion Models: Ho et al.
